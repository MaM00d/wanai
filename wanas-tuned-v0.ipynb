{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "nCEL7HvfsY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: torch in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (0.18.0+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip3 install torch torchvision torchaudio\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install peft\n",
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jukit_cell_id": "KwYlAwiGnU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch, peft\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jukit_cell_id": "ph7BpuuNu4"
   },
   "outputs": [],
   "source": [
    "# specify how to quantize the model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jukit_cell_id": "bJiEV2rkNZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jukit_cell_id": "a6wRStxEew"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"FreedomIntelligence/AceGPT-13B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, quantization_config=quantization_config, device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jukit_cell_id": "PfI0aEsFKv"
   },
   "outputs": [],
   "source": [
    "def create_prompt(history, patient, doctor):\n",
    "    prompt_template = (\n",
    "        f\"### HISTORY\\n{history}\\n\\n### PATIENT\\n{patient}\\n\\n### DOCTOR\\n{doctor}</s>\"\n",
    "    )\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jukit_cell_id": "rEipDtIjCQ"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig.from_pretrained(\n",
    "    \"M:\\.hfcache\\hub\\models--hader1234--wanas_trained\\snapshots\\d750e8bd4279fa561fe295af85e70a3229ad7079\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.temperature=None\n",
    "model.generation_config.top_p=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jukit_cell_id": "r8cjt4FwzB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 4096}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
     ]
    }
   ],
   "source": [
    "mergedmodel = model.merge_and_unload()\n",
    "\n",
    "mergedmodel.save_pretrained(\"./tunedmodel\", do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jukit_cell_id": "L29p09uzLG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\quantizers\\auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6707289cabfd4f628b27dbf206bcdc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\mahmo\\AppData\\Local\\Temp\\ipykernel_17060\\1676050668.py\", line 3, in <module>\n",
      "    elmodel = AutoModelForCausalLM.from_pretrained(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 563, in from_pretrained\n",
      "    def insert_head_doc(docstring, head_doc=\"\"):\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3677, in from_pretrained\n",
      "    start_states = hidden_states.gather(-2, start_positions).squeeze(-2)  # shape (bsz, hsz)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4104, in _load_pretrained_model\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 888, in _load_state_dict_into_meta_model\n",
      "    elif attention_mask.dim() == 2:\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py\", line 204, in create_quantized_param\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py\", line 278, in from_prequantized\n",
      "    self = torch.Tensor._make_subclass(cls, data.to(device))\n",
      "                                            ^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 34.00 MiB. GPU \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\mahmo\\anaconda3\\envs\\wanas\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "elmodel = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./tunedmodel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "iqL3HMpCqz"
   },
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "save_directory = \"onnx/\"\n",
    "\n",
    "# Load a model from transformers and export it to ONNX\n",
    "ort_model = ORTModelForSequenceClassification.from_pretrained(mergedmodel, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(mergedmodel)\n",
    "\n",
    "# Save the onnx model and tokenizer\n",
    "ort_model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "BaFBVgPlLF"
   },
   "outputs": [],
   "source": [
    "text = create_prompt(\"\", \"اهلا يا دكتور\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jukit_cell_id": "wLo5wkawTI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### HISTORY\n",
      "\n",
      "\n",
      "### PATIENT\n",
      "اهلا يا دكتور\n",
      "\n",
      "### DOCTOR\n",
      " مرحبا يا اخي كيف حالك ؟\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jukit_cell_id": "v0xa0yOBA6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.16.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from onnx) (1.26.3)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Downloading protobuf-5.26.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading onnx-1.16.0-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 0.0/14.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.4 MB 960.0 kB/s eta 0:00:15\n",
      "   ---------------------------------------- 0.1/14.4 MB 1.6 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.3/14.4 MB 2.5 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/14.4 MB 2.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.7/14.4 MB 2.9 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/14.4 MB 3.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/14.4 MB 3.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/14.4 MB 3.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.4/14.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.5/14.4 MB 3.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.6/14.4 MB 3.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/14.4 MB 3.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/14.4 MB 3.2 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.8/14.4 MB 3.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.3/14.4 MB 3.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.5/14.4 MB 3.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.7/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.9/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.1/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.2/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.4/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.6/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.7/14.4 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.9/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.1/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.3/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.9/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.0/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.2/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.3/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.5/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.6/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.8/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.9/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.1/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.2/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.4/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.6/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.7/14.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.9/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.0/14.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.2/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.4/14.4 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.5/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.7/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.9/14.4 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.2/14.4 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.5/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.7/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.9/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.1/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.6/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.7/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.9/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.1/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.2/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.4/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.6/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.8/14.4 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.9/14.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.1/14.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.3/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.6/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.8/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.0/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.2/14.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.3/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.5/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.7/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.9/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.0/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.2/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.4/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.7/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.1/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.4/14.4 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.26.1-cp310-abi3-win_amd64.whl (420 kB)\n",
      "   ---------------------------------------- 0.0/420.9 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 163.8/420.9 kB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 348.2/420.9 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 420.9/420.9 kB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, onnx\n",
      "Successfully installed onnx-1.16.0 protobuf-5.26.1\n",
      "Collecting onnxscript\n",
      "  Downloading onnxscript-0.1.0.dev20240520-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from onnxscript) (1.26.3)\n",
      "Requirement already satisfied: onnx>=1.16 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from onnxscript) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from onnxscript) (4.11.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mahmo\\anaconda3\\envs\\wanas\\lib\\site-packages (from onnx>=1.16->onnxscript) (5.26.1)\n",
      "Downloading onnxscript-0.1.0.dev20240520-py3-none-any.whl (603 kB)\n",
      "   ---------------------------------------- 0.0/604.0 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/604.0 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 81.9/604.0 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 245.8/604.0 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 419.8/604.0 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 604.0/604.0 kB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: onnxscript\n",
      "Successfully installed onnxscript-0.1.0.dev20240520\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# from pathlib import Path\n",
    "# import transformers\n",
    "# from transformers.onnx import FeaturesManager\n",
    "# from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification!pip install onnx\n",
    "# !pip install onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jukit_cell_id": "dkbhsbuqoT"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"llama is not supported yet. Only ['albert', 'bart', 'beit', 'bert', 'big-bird', 'bigbird-pegasus', 'blenderbot', 'blenderbot-small', 'bloom', 'camembert', 'clip', 'codegen', 'convbert', 'convnext', 'data2vec-text', 'data2vec-vision', 'deberta', 'deberta-v2', 'deit', 'detr', 'distilbert', 'electra', 'flaubert', 'gpt2', 'gptj', 'gpt-neo', 'groupvit', 'ibert', 'imagegpt', 'layoutlm', 'layoutlmv3', 'levit', 'longt5', 'longformer', 'marian', 'mbart', 'mobilebert', 'mobilenet-v1', 'mobilenet-v2', 'mobilevit', 'mt5', 'm2m-100', 'owlvit', 'perceiver', 'poolformer', 'rembert', 'resnet', 'roberta', 'roformer', 'segformer', 'squeezebert', 'swin', 't5', 'vision-encoder-decoder', 'vit', 'whisper', 'xlm', 'xlm-roberta', 'yolos'] are supported. If you want to support llama please propose a PR or open up an issue.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# load config\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model_kind, model_onnx_config \u001b[38;5;241m=\u001b[39m FeaturesManager\u001b[38;5;241m.\u001b[39mcheck_supported_model_or_raise(model, feature\u001b[38;5;241m=\u001b[39mfeature)\n\u001b[0;32m      8\u001b[0m onnx_config \u001b[38;5;241m=\u001b[39m model_onnx_config(model\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# export\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\onnx\\features.py:728\u001b[0m, in \u001b[0;36mFeaturesManager.check_supported_model_or_raise\u001b[1;34m(model, feature)\u001b[0m\n\u001b[0;32m    726\u001b[0m model_type \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    727\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 728\u001b[0m model_features \u001b[38;5;241m=\u001b[39m FeaturesManager\u001b[38;5;241m.\u001b[39mget_supported_features_for_model_type(model_type, model_name\u001b[38;5;241m=\u001b[39mmodel_name)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_features:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    731\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support feature \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Supported values are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    732\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\wanas\\Lib\\site-packages\\transformers\\onnx\\features.py:575\u001b[0m, in \u001b[0;36mFeaturesManager.get_supported_features_for_model_type\u001b[1;34m(model_type, model_name)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m FeaturesManager\u001b[38;5;241m.\u001b[39m_SUPPORTED_MODEL_TYPE:\n\u001b[0;32m    574\u001b[0m     model_type_and_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;28;01melse\u001b[39;00m model_type\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type_and_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported yet. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(FeaturesManager\u001b[38;5;241m.\u001b[39m_SUPPORTED_MODEL_TYPE\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want to support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m please propose a PR or open up an issue.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m     )\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FeaturesManager\u001b[38;5;241m.\u001b[39m_SUPPORTED_MODEL_TYPE[model_type]\n",
      "\u001b[1;31mKeyError\u001b[0m: \"llama is not supported yet. Only ['albert', 'bart', 'beit', 'bert', 'big-bird', 'bigbird-pegasus', 'blenderbot', 'blenderbot-small', 'bloom', 'camembert', 'clip', 'codegen', 'convbert', 'convnext', 'data2vec-text', 'data2vec-vision', 'deberta', 'deberta-v2', 'deit', 'detr', 'distilbert', 'electra', 'flaubert', 'gpt2', 'gptj', 'gpt-neo', 'groupvit', 'ibert', 'imagegpt', 'layoutlm', 'layoutlmv3', 'levit', 'longt5', 'longformer', 'marian', 'mbart', 'mobilebert', 'mobilenet-v1', 'mobilenet-v2', 'mobilevit', 'mt5', 'm2m-100', 'owlvit', 'perceiver', 'poolformer', 'rembert', 'resnet', 'roberta', 'roformer', 'segformer', 'squeezebert', 'swin', 't5', 'vision-encoder-decoder', 'vit', 'whisper', 'xlm', 'xlm-roberta', 'yolos'] are supported. If you want to support llama please propose a PR or open up an issue.\""
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "# import transformers\n",
    "# from transformers.onnx import FeaturesManager\n",
    "# from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
    "# feature = \"text-generation\"\n",
    "# # load config\n",
    "# model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature=feature)\n",
    "# onnx_config = model_onnx_config(model.config)\n",
    "#\n",
    "# # export\n",
    "# onnx_inputs, onnx_outputs = transformers.onnx.export(\n",
    "#         preprocessor=tokenizer,\n",
    "#         model=model,\n",
    "#         config=onnx_config,\n",
    "#         opset=13,\n",
    "#         output=Path(\"trfs-model.onnx\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "uLA60Y96Ri"
   },
   "outputs": [],
   "source": [
    "text = create_prompt(\"\", \"ليه مموتش مريم\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jukit_cell_id": "zxumPTHs1y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### HISTORY\n",
      "\n",
      "\n",
      "### PATIENT\n",
      "انا عايز اموت مريم  ازاى اموت مريم لو سمحت\n",
      "\n",
      "### DOCTOR\n",
      " انت مش عايز تموت مريم انت عايز تموت مريم لو سمحت \n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "NpR37d3LEF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
